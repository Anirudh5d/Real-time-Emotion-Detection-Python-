{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPQQ0ryHjoT7dTRA+jNKGFr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"NmD-rsRydEt9"},"outputs":[],"source":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kV3TB_2Kedkr","executionInfo":{"status":"ok","timestamp":1694180435630,"user_tz":-330,"elapsed":28477,"user":{"displayName":"Aniruddha Deshpande","userId":"13056721732630023561"}},"outputId":"0adccb69-d6ac-454f-e840-013fd9919233"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install Keras-Preprocessing"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Buo803UfoYp","executionInfo":{"status":"ok","timestamp":1693483707165,"user_tz":-330,"elapsed":5478,"user":{"displayName":"Aniruddha Deshpande","userId":"13056721732630023561"}},"outputId":"9cbfa223-6d35-4399-cbbb-37281ece1aad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting Keras-Preprocessing\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.23.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.16.0)\n","Installing collected packages: Keras-Preprocessing\n","Successfully installed Keras-Preprocessing-1.1.2\n"]}]},{"cell_type":"code","source":["from keras.utils import to_categorical\n","from tensorflow.keras.utils import load_img\n","from keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,Flatten,Conv2D,BatchNormalization,Activation,MaxPooling2D\n","from keras.models import Model,Sequential\n","from keras.optimizers import Adam,SGD,RMSprop\n","import os\n","import pandas as pd\n","import numpy as np\n","import cv2 as cv\n","from tqdm.notebook import tqdm\n","from keras.preprocessing.image import ImageDataGenerator"],"metadata":{"id":"I2-oIjSneesy","executionInfo":{"status":"ok","timestamp":1694192783597,"user_tz":-330,"elapsed":514,"user":{"displayName":"Aniruddha Deshpande","userId":"13056721732630023561"}}},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"GbXLx8JfDLEx"}},{"cell_type":"code","source":["Main_dir = '/content/drive/MyDrive/Emotional Detector Python /images/'\n"],"metadata":{"id":"PAmjh2V6fGt6","executionInfo":{"status":"ok","timestamp":1694192581678,"user_tz":-330,"elapsed":510,"user":{"displayName":"Aniruddha Deshpande","userId":"13056721732630023561"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["batch_size  = 128\n","\n","datagen_train  = ImageDataGenerator()\n","datagen_val = ImageDataGenerator()\n","\n","train_dataset = datagen_train.flow_from_directory(Main_dir+\"train\",\n","                                              target_size = (48,48),\n","                                              color_mode = \"grayscale\",\n","                                              batch_size=batch_size,\n","                                              class_mode='categorical',\n","                                              shuffle=True)\n","\n","\n","test_dataset = datagen_val.flow_from_directory(Main_dir+\"validation\",\n","                                              target_size = (48,48),\n","                                              color_mode = \"grayscale\",\n","                                              batch_size=batch_size,\n","                                              class_mode='categorical',\n","                                              shuffle=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TdFtqZbSvcup","executionInfo":{"status":"ok","timestamp":1694192705985,"user_tz":-330,"elapsed":1982,"user":{"displayName":"Aniruddha Deshpande","userId":"13056721732630023561"}},"outputId":"e091ebc8-faa1-4606-c95c-67e500690c6d"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 28821 images belonging to 7 classes.\n","Found 1690 images belonging to 7 classes.\n"]}]},{"cell_type":"code","source":["model = Sequential()\n","\n","#1st CNN layer\n","model.add(Conv2D(64,(3,3),padding = 'same',input_shape = (48,48,1)))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size = (2,2)))\n","model.add(Dropout(0.25))\n","\n","#2nd CNN layer\n","model.add(Conv2D(128,(5,5),padding = 'same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size = (2,2)))\n","model.add(Dropout (0.25))\n","\n","#3rd CNN layer\n","model.add(Conv2D(512,(3,3),padding = 'same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size = (2,2)))\n","model.add(Dropout (0.25))\n","\n","#4th CNN layer\n","model.add(Conv2D(512,(3,3), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","\n","#Fully connected 1st layer\n","model.add(Dense(256))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(Dropout(0.25))\n","\n","\n","# Fully connected layer 2nd layer\n","model.add(Dense(512))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(Dropout(0.25))\n","\n","model.add(Dense(7, activation='softmax'))\n","\n","\n","\n","opt = Adam(lr = 0.0001)\n","model.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ZR0vAsTwc8K","executionInfo":{"status":"ok","timestamp":1694192820219,"user_tz":-330,"elapsed":1404,"user":{"displayName":"Aniruddha Deshpande","userId":"13056721732630023561"}},"outputId":"e4b01d91-f99a-4e13-a0f9-fe0ad669952d"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_4 (Conv2D)           (None, 48, 48, 64)        640       \n","                                                                 \n"," batch_normalization (BatchN  (None, 48, 48, 64)       256       \n"," ormalization)                                                   \n","                                                                 \n"," activation (Activation)     (None, 48, 48, 64)        0         \n","                                                                 \n"," max_pooling2d_4 (MaxPooling  (None, 24, 24, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_6 (Dropout)         (None, 24, 24, 64)        0         \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 24, 24, 128)       204928    \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 24, 24, 128)      512       \n"," hNormalization)                                                 \n","                                                                 \n"," activation_1 (Activation)   (None, 24, 24, 128)       0         \n","                                                                 \n"," max_pooling2d_5 (MaxPooling  (None, 12, 12, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_7 (Dropout)         (None, 12, 12, 128)       0         \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 12, 12, 512)       590336    \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 12, 12, 512)      2048      \n"," hNormalization)                                                 \n","                                                                 \n"," activation_2 (Activation)   (None, 12, 12, 512)       0         \n","                                                                 \n"," max_pooling2d_6 (MaxPooling  (None, 6, 6, 512)        0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_8 (Dropout)         (None, 6, 6, 512)         0         \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 6, 6, 512)         2359808   \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 6, 6, 512)        2048      \n"," hNormalization)                                                 \n","                                                                 \n"," activation_3 (Activation)   (None, 6, 6, 512)         0         \n","                                                                 \n"," max_pooling2d_7 (MaxPooling  (None, 3, 3, 512)        0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_9 (Dropout)         (None, 3, 3, 512)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 4608)              0         \n","                                                                 \n"," dense_3 (Dense)             (None, 256)               1179904   \n","                                                                 \n"," batch_normalization_4 (Batc  (None, 256)              1024      \n"," hNormalization)                                                 \n","                                                                 \n"," activation_4 (Activation)   (None, 256)               0         \n","                                                                 \n"," dropout_10 (Dropout)        (None, 256)               0         \n","                                                                 \n"," dense_4 (Dense)             (None, 512)               131584    \n","                                                                 \n"," batch_normalization_5 (Batc  (None, 512)              2048      \n"," hNormalization)                                                 \n","                                                                 \n"," activation_5 (Activation)   (None, 512)               0         \n","                                                                 \n"," dropout_11 (Dropout)        (None, 512)               0         \n","                                                                 \n"," dense_5 (Dense)             (None, 7)                 3591      \n","                                                                 \n","=================================================================\n","Total params: 4,478,727\n","Trainable params: 4,474,759\n","Non-trainable params: 3,968\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n"]}]},{"cell_type":"code","source":["model1 = Sequential()\n","\n","#1st CNN layer\n","model1.add(Conv2D(64,(3,3),padding = 'same',input_shape = (48,48,1)))\n","model1.add(BatchNormalization())\n","model1.add(Activation('relu'))\n","model1.add(MaxPooling2D(pool_size = (2,2)))\n","model1.add(Dropout(0.25))\n","\n","#2nd CNN layer\n","model1.add(Conv2D(128,(5,5),padding = 'same'))\n","model1.add(BatchNormalization())\n","model1.add(Activation('relu'))\n","model1.add(MaxPooling2D(pool_size = (2,2)))\n","model1.add(Dropout (0.25))\n","\n","#3rd CNN layer\n","model1.add(Conv2D(512,(3,3),padding = 'same'))\n","model1.add(BatchNormalization())\n","model1.add(Activation('relu'))\n","model1.add(MaxPooling2D(pool_size = (2,2)))\n","model1.add(Dropout (0.25))\n","\n","#4th CNN layer\n","model1.add(Conv2D(512,(3,3), padding='same'))\n","model1.add(BatchNormalization())\n","model1.add(Activation('relu'))\n","model1.add(MaxPooling2D(pool_size=(2, 2)))\n","model1.add(Dropout(0.25))\n","\n","model1.add(Flatten())\n","\n","#Fully connected 1st layer\n","model1.add(Dense(256))\n","model1.add(BatchNormalization())\n","model1.add(Activation('relu'))\n","model1.add(Dropout(0.25))\n","\n","\n","# Fully connected layer 2nd layer\n","model1.add(Dense(512))\n","model1.add(BatchNormalization())\n","model1.add(Activation('relu'))\n","model1.add(Dropout(0.25))\n","\n","model1.add(Dense(7, activation='softmax'))\n","\n","\n","\n","opt = Adam(lr = 0.0001)\n","model1.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])\n","model1.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Axwa-vPw2M08","executionInfo":{"status":"ok","timestamp":1694194354591,"user_tz":-330,"elapsed":14777,"user":{"displayName":"Aniruddha Deshpande","userId":"13056721732630023561"}},"outputId":"5f7567f9-afc7-409b-9686-d01625309f10"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_8 (Conv2D)           (None, 48, 48, 64)        640       \n","                                                                 \n"," batch_normalization_6 (Batc  (None, 48, 48, 64)       256       \n"," hNormalization)                                                 \n","                                                                 \n"," activation_6 (Activation)   (None, 48, 48, 64)        0         \n","                                                                 \n"," max_pooling2d_8 (MaxPooling  (None, 24, 24, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_12 (Dropout)        (None, 24, 24, 64)        0         \n","                                                                 \n"," conv2d_9 (Conv2D)           (None, 24, 24, 128)       204928    \n","                                                                 \n"," batch_normalization_7 (Batc  (None, 24, 24, 128)      512       \n"," hNormalization)                                                 \n","                                                                 \n"," activation_7 (Activation)   (None, 24, 24, 128)       0         \n","                                                                 \n"," max_pooling2d_9 (MaxPooling  (None, 12, 12, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_13 (Dropout)        (None, 12, 12, 128)       0         \n","                                                                 \n"," conv2d_10 (Conv2D)          (None, 12, 12, 512)       590336    \n","                                                                 \n"," batch_normalization_8 (Batc  (None, 12, 12, 512)      2048      \n"," hNormalization)                                                 \n","                                                                 \n"," activation_8 (Activation)   (None, 12, 12, 512)       0         \n","                                                                 \n"," max_pooling2d_10 (MaxPoolin  (None, 6, 6, 512)        0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_14 (Dropout)        (None, 6, 6, 512)         0         \n","                                                                 \n"," conv2d_11 (Conv2D)          (None, 6, 6, 512)         2359808   \n","                                                                 \n"," batch_normalization_9 (Batc  (None, 6, 6, 512)        2048      \n"," hNormalization)                                                 \n","                                                                 \n"," activation_9 (Activation)   (None, 6, 6, 512)         0         \n","                                                                 \n"," max_pooling2d_11 (MaxPoolin  (None, 3, 3, 512)        0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_15 (Dropout)        (None, 3, 3, 512)         0         \n","                                                                 \n"," flatten_1 (Flatten)         (None, 4608)              0         \n","                                                                 \n"," dense_6 (Dense)             (None, 256)               1179904   \n","                                                                 \n"," batch_normalization_10 (Bat  (None, 256)              1024      \n"," chNormalization)                                                \n","                                                                 \n"," activation_10 (Activation)  (None, 256)               0         \n","                                                                 \n"," dropout_16 (Dropout)        (None, 256)               0         \n","                                                                 \n"," dense_7 (Dense)             (None, 512)               131584    \n","                                                                 \n"," batch_normalization_11 (Bat  (None, 512)              2048      \n"," chNormalization)                                                \n","                                                                 \n"," activation_11 (Activation)  (None, 512)               0         \n","                                                                 \n"," dropout_17 (Dropout)        (None, 512)               0         \n","                                                                 \n"," dense_8 (Dense)             (None, 7)                 3591      \n","                                                                 \n","=================================================================\n","Total params: 4,478,727\n","Trainable params: 4,474,759\n","Non-trainable params: 3,968\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n"]}]},{"cell_type":"code","source":["model1.compile(loss='categorical_crossentropy',\n","              optimizer = Adam(lr=0.001),\n","              metrics=['accuracy'])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NX0bJ7Vf2oI1","executionInfo":{"status":"ok","timestamp":1694194452467,"user_tz":-330,"elapsed":449,"user":{"displayName":"Aniruddha Deshpande","userId":"13056721732630023561"}},"outputId":"bc6cf702-a721-4398-ffcc-13ec55a68e86"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n"]}]},{"cell_type":"code","source":["from keras.optimizers import RMSprop,SGD,Adam\n","from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","checkpoint = ModelCheckpoint(\"./model.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n","early_stopping = EarlyStopping(monitor='val_loss',\n","                          min_delta=0,\n","                          patience=3,\n","                          verbose=1,\n","                          restore_best_weights=True\n","                          )\n","\n","reduce_learningrate = ReduceLROnPlateau(monitor='val_loss',\n","                              factor=0.2,\n","                              patience=3,\n","                              verbose=1,\n","                              min_delta=0.0001)\n","\n","callbacks_list = [early_stopping,checkpoint,reduce_learningrate]\n","\n","epochs = 48\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer = Adam(lr=0.001),\n","              metrics=['accuracy'])"],"metadata":{"id":"Mn79FOxswwO6","executionInfo":{"status":"aborted","timestamp":1694194836414,"user_tz":-330,"elapsed":15,"user":{"displayName":"Aniruddha Deshpande","userId":"13056721732630023561"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["callback= [reduce_learningrate]"],"metadata":{"id":"zfbOQ7d94WSl","executionInfo":{"status":"ok","timestamp":1694194957109,"user_tz":-330,"elapsed":1128,"user":{"displayName":"Aniruddha Deshpande","userId":"13056721732630023561"}}},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":["with early stopping"],"metadata":{"id":"BJAL5ioa8zBN"}},{"cell_type":"code","source":["history = model1.fit(train_dataset,epochs = 14,steps_per_epoch=train_dataset.n//train_dataset.batch_size,\n","                    validation_data = test_dataset,\n","                    validation_steps = test_dataset.n//test_dataset.batch_size,\n","                    callbacks=callback)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zIBJpj1L2pPm","executionInfo":{"status":"ok","timestamp":1694195558697,"user_tz":-330,"elapsed":164802,"user":{"displayName":"Aniruddha Deshpande","userId":"13056721732630023561"}},"outputId":"e6a867e6-62f8-4a43-9653-5b8db65ca8a4"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/14\n","225/225 [==============================] - 41s 183ms/step - loss: 1.0093 - accuracy: 0.6189 - val_loss: 0.9168 - val_accuracy: 0.6725 - lr: 0.0010\n","Epoch 2/14\n","225/225 [==============================] - 39s 173ms/step - loss: 0.9685 - accuracy: 0.6358 - val_loss: 1.2040 - val_accuracy: 0.5487 - lr: 0.0010\n","Epoch 3/14\n","225/225 [==============================] - 39s 173ms/step - loss: 0.9191 - accuracy: 0.6536 - val_loss: 1.2616 - val_accuracy: 0.5018 - lr: 0.0010\n","Epoch 4/14\n","225/225 [==============================] - ETA: 0s - loss: 0.8850 - accuracy: 0.6651\n","Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n","225/225 [==============================] - 39s 175ms/step - loss: 0.8850 - accuracy: 0.6651 - val_loss: 1.2464 - val_accuracy: 0.5571 - lr: 0.0010\n","Epoch 5/14\n","225/225 [==============================] - 39s 172ms/step - loss: 0.7599 - accuracy: 0.7184 - val_loss: 1.0414 - val_accuracy: 0.6316 - lr: 2.0000e-04\n","Epoch 6/14\n","225/225 [==============================] - 38s 170ms/step - loss: 0.7130 - accuracy: 0.7352 - val_loss: 0.9349 - val_accuracy: 0.6815 - lr: 2.0000e-04\n","Epoch 7/14\n","225/225 [==============================] - ETA: 0s - loss: 0.6774 - accuracy: 0.7464\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n","225/225 [==============================] - 38s 170ms/step - loss: 0.6774 - accuracy: 0.7464 - val_loss: 1.0556 - val_accuracy: 0.6352 - lr: 2.0000e-04\n","Epoch 8/14\n","225/225 [==============================] - 38s 169ms/step - loss: 0.6353 - accuracy: 0.7642 - val_loss: 0.9566 - val_accuracy: 0.6725 - lr: 4.0000e-05\n","Epoch 9/14\n","225/225 [==============================] - 38s 170ms/step - loss: 0.6208 - accuracy: 0.7698 - val_loss: 0.9913 - val_accuracy: 0.6599 - lr: 4.0000e-05\n","Epoch 10/14\n","225/225 [==============================] - ETA: 0s - loss: 0.6130 - accuracy: 0.7712\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n","225/225 [==============================] - 39s 172ms/step - loss: 0.6130 - accuracy: 0.7712 - val_loss: 0.9703 - val_accuracy: 0.6677 - lr: 4.0000e-05\n","Epoch 11/14\n","225/225 [==============================] - 39s 173ms/step - loss: 0.6048 - accuracy: 0.7769 - val_loss: 0.9606 - val_accuracy: 0.6677 - lr: 8.0000e-06\n","Epoch 12/14\n","225/225 [==============================] - 38s 168ms/step - loss: 0.5967 - accuracy: 0.7774 - val_loss: 0.9392 - val_accuracy: 0.6749 - lr: 8.0000e-06\n","Epoch 13/14\n","225/225 [==============================] - ETA: 0s - loss: 0.6043 - accuracy: 0.7794\n","Epoch 13: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n","225/225 [==============================] - 39s 172ms/step - loss: 0.6043 - accuracy: 0.7794 - val_loss: 0.9680 - val_accuracy: 0.6689 - lr: 8.0000e-06\n","Epoch 14/14\n","225/225 [==============================] - 38s 170ms/step - loss: 0.5995 - accuracy: 0.7774 - val_loss: 0.9630 - val_accuracy: 0.6707 - lr: 1.6000e-06\n"]}]},{"cell_type":"code","source":["model1.save('/content/drive/MyDrive/Emotional Detector Python /models/model1.h5')"],"metadata":{"id":"s5RcT7Gd7NfA","executionInfo":{"status":"ok","timestamp":1694195686500,"user_tz":-330,"elapsed":438,"user":{"displayName":"Aniruddha Deshpande","userId":"13056721732630023561"}}},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":["without early stopping\n"],"metadata":{"id":"Lx8GSZkH8tvA"}},{"cell_type":"code","source":["history = model.fit(train_dataset,epochs = 48,steps_per_epoch=train_dataset.n//train_dataset.batch_size,\n","                    validation_data = test_dataset,\n","                    validation_steps = test_dataset.n//test_dataset.batch_size,\n","                    callbacks=callbacks_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uAYYOAVyyPiI","executionInfo":{"status":"ok","timestamp":1694193656968,"user_tz":-330,"elapsed":305780,"user":{"displayName":"Aniruddha Deshpande","userId":"13056721732630023561"}},"outputId":"219abbe2-b5da-4f01-c5a8-588ffffba0dd"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/48\n","225/225 [==============================] - ETA: 0s - loss: 1.0310 - accuracy: 0.6081"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r225/225 [==============================] - 47s 209ms/step - loss: 1.0310 - accuracy: 0.6081 - val_loss: 0.9276 - val_accuracy: 0.6526 - lr: 0.0010\n","Epoch 2/48\n","225/225 [==============================] - ETA: 0s - loss: 0.9829 - accuracy: 0.6298"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r225/225 [==============================] - 44s 195ms/step - loss: 0.9829 - accuracy: 0.6298 - val_loss: 1.2347 - val_accuracy: 0.5475 - lr: 0.0010\n","Epoch 3/48\n","225/225 [==============================] - ETA: 0s - loss: 0.9369 - accuracy: 0.6466"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r225/225 [==============================] - 43s 192ms/step - loss: 0.9369 - accuracy: 0.6466 - val_loss: 0.8325 - val_accuracy: 0.7037 - lr: 0.0010\n","Epoch 4/48\n","225/225 [==============================] - ETA: 0s - loss: 0.9018 - accuracy: 0.6578"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r225/225 [==============================] - 44s 196ms/step - loss: 0.9018 - accuracy: 0.6578 - val_loss: 1.4693 - val_accuracy: 0.4850 - lr: 0.0010\n","Epoch 5/48\n","225/225 [==============================] - ETA: 0s - loss: 0.8567 - accuracy: 0.6781"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r225/225 [==============================] - 46s 203ms/step - loss: 0.8567 - accuracy: 0.6781 - val_loss: 1.2899 - val_accuracy: 0.5234 - lr: 0.0010\n","Epoch 6/48\n","225/225 [==============================] - ETA: 0s - loss: 0.8065 - accuracy: 0.6989Restoring model weights from the end of the best epoch: 3.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n","225/225 [==============================] - 45s 199ms/step - loss: 0.8065 - accuracy: 0.6989 - val_loss: 1.0057 - val_accuracy: 0.6274 - lr: 0.0010\n","Epoch 6: early stopping\n"]}]},{"cell_type":"code","source":["model.save('/content/drive/MyDrive/Emotional Detector Python /models/model.h5')"],"metadata":{"id":"V-LvxjUz7s5t","executionInfo":{"status":"ok","timestamp":1694195718067,"user_tz":-330,"elapsed":598,"user":{"displayName":"Aniruddha Deshpande","userId":"13056721732630023561"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"G_w8Zh6PqBKE"},"execution_count":null,"outputs":[]}]}